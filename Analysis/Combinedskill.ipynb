{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyBKT.models import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installed pyBKT from pip\n",
    "\n",
    "#pip install pyBKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seed chosen to consistently replicate results (avoiding randomness)\n",
    "model = Model(seed = 60, num_fits = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching the dataset from github\n",
    "model.fetch_dataset(\"https://raw.githubusercontent.com/lishaparmar13/H5P-Enhanced-BKT/main/CS.csv\",'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ï»¿Row</th>\n",
       "      <th>Anon Student Id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Problem Hierarchy</th>\n",
       "      <th>Problem Name</th>\n",
       "      <th>question_id</th>\n",
       "      <th>Step Start Time</th>\n",
       "      <th>Step End Time</th>\n",
       "      <th>Correct First Attempt</th>\n",
       "      <th>Step Duration (sec)</th>\n",
       "      <th>Answer Type</th>\n",
       "      <th>KC(Default)</th>\n",
       "      <th>Opportunity (Default)</th>\n",
       "      <th>skill_id</th>\n",
       "      <th>template_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Perimeter</td>\n",
       "      <td>1</td>\n",
       "      <td>11-07-2023 07:25</td>\n",
       "      <td>11-07-2023 07:27</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>Single Choice set</td>\n",
       "      <td>Geometry</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Perimeter</td>\n",
       "      <td>1</td>\n",
       "      <td>18-07-2023 04:22</td>\n",
       "      <td>18-07-2023 04:28</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>Single Choice set</td>\n",
       "      <td>Geometry</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Perimeter</td>\n",
       "      <td>1</td>\n",
       "      <td>20-07-2023 04:23</td>\n",
       "      <td>20-07-2023 04:23</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Single Choice set</td>\n",
       "      <td>Geometry</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>Perimeter</td>\n",
       "      <td>1</td>\n",
       "      <td>17-07-2023 14:25</td>\n",
       "      <td>17-07-2023 14:26</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>Single Choice set</td>\n",
       "      <td>Geometry</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>Perimeter</td>\n",
       "      <td>1</td>\n",
       "      <td>18-07-2023 21:15</td>\n",
       "      <td>18-07-2023 21:16</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>Single Choice set</td>\n",
       "      <td>Geometry</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ï»¿Row  Anon Student Id Age  Problem Hierarchy Problem Name  question_id  \\\n",
       "0       2                2  13                  1    Perimeter            1   \n",
       "1      17               17  13                  1    Perimeter            1   \n",
       "2      19               19  13                  1    Perimeter            1   \n",
       "3      16               16  14                  1    Perimeter            1   \n",
       "4      18               18  14                  1    Perimeter            1   \n",
       "\n",
       "    Step Start Time     Step End Time  Correct First Attempt  \\\n",
       "0  11-07-2023 07:25  11-07-2023 07:27                      1   \n",
       "1  18-07-2023 04:22  18-07-2023 04:28                      1   \n",
       "2  20-07-2023 04:23  20-07-2023 04:23                      1   \n",
       "3  17-07-2023 14:25  17-07-2023 14:26                      1   \n",
       "4  18-07-2023 21:15  18-07-2023 21:16                      1   \n",
       "\n",
       "   Step Duration (sec)        Answer Type KC(Default)  Opportunity (Default)  \\\n",
       "0                   60  Single Choice set    Geometry                      1   \n",
       "1                  300  Single Choice set    Geometry                      1   \n",
       "2                    5  Single Choice set    Geometry                      1   \n",
       "3                   42  Single Choice set    Geometry                      1   \n",
       "4                   60  Single Choice set    Geometry                      1   \n",
       "\n",
       "   skill_id  template_id  \n",
       "0         9            6  \n",
       "1         9            6  \n",
       "2         9            6  \n",
       "3         9            6  \n",
       "4         9            6  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(r\"CS.csv\", encoding ='latin')\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the data to be later used for predictions\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model using training dataset\n",
    "model.fit(data = train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted Skills:\n",
      "Algebra and Fractions\n",
      "Algebra\n",
      "Numbers and Geometry and Percentages\n",
      "Ratio and Proportion\n",
      "Numbers and Algebra and Fractions\n",
      "Fractions\n",
      "Numbers and Percentages and Ratio and Proportion\n",
      "Numbers and Geometry and Fractions\n",
      "Geometry\n"
     ]
    }
   ],
   "source": [
    "#List of all skill names from the dataset\n",
    "print(\"Fitted Skills:\\n%s\" % '\\n'.join(model.coef_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can be used to find a particular match based on skill name mentioned\n",
    "model.fit(data= train_df, skills = \".*Fractions.*\")\n",
    "print(\"Fitted Skills:\\n%s\" % '\\n'.join(model.coef_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Evaluate with the default RMSE then specify AUC.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(data \u001b[39m=\u001b[39;49m train_df)\n\u001b[0;32m      3\u001b[0m training_rmse \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(data \u001b[39m=\u001b[39m df)\n\u001b[0;32m      4\u001b[0m training_auc \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(data \u001b[39m=\u001b[39m train_df, metric \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauc\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\site-packages\\pyBKT\\models\\Model.py:80\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, data_path, data, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_param_init:\n\u001b[0;32m     79\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_model \u001b[39m=\u001b[39m {}\n\u001b[1;32m---> 80\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpartial_fit(data_path \u001b[39m=\u001b[39m data_path, data \u001b[39m=\u001b[39m data, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\site-packages\\pyBKT\\models\\Model.py:111\u001b[0m, in \u001b[0;36mModel.partial_fit\u001b[1;34m(self, data_path, data, **kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_param([\u001b[39m'\u001b[39m\u001b[39mskills\u001b[39m\u001b[39m'\u001b[39m], {\u001b[39m'\u001b[39m\u001b[39mskills\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlist\u001b[39m(all_data\u001b[39m.\u001b[39mkeys())})\n\u001b[0;32m    110\u001b[0m \u001b[39mfor\u001b[39;00m skill \u001b[39min\u001b[39;00m all_data:\n\u001b[1;32m--> 111\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_model[skill] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(all_data[skill], skill, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforgets, \n\u001b[0;32m    112\u001b[0m                                       preload \u001b[39m=\u001b[39;49m kwargs[\u001b[39m'\u001b[39;49m\u001b[39mpreload\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39mif\u001b[39;49;00m \u001b[39m'\u001b[39;49m\u001b[39mpreload\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39min\u001b[39;49;00m kwargs \u001b[39melse\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_param_init \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\site-packages\\pyBKT\\models\\Model.py:424\u001b[0m, in \u001b[0;36mModel._fit\u001b[1;34m(self, data, skill, forgets, preload)\u001b[0m\n\u001b[0;32m    422\u001b[0m             optional_args[\u001b[39m'\u001b[39m\u001b[39mfixed\u001b[39m\u001b[39m'\u001b[39m][var] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfixed[skill][var]\n\u001b[0;32m    423\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m preload:\n\u001b[1;32m--> 424\u001b[0m     fitmodel, log_likelihoods \u001b[39m=\u001b[39m EM_fit\u001b[39m.\u001b[39mEM_fit(fitmodel, data, parallel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptional_args)\n\u001b[0;32m    425\u001b[0m     \u001b[39mif\u001b[39;00m log_likelihoods[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m best_likelihood:\n\u001b[0;32m    426\u001b[0m         best_likelihood \u001b[39m=\u001b[39m log_likelihoods[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\site-packages\\pyBKT\\fit\\EM_fit.py:36\u001b[0m, in \u001b[0;36mEM_fit\u001b[1;34m(model, data, tol, maxiter, parallel, fixed)\u001b[0m\n\u001b[0;32m     33\u001b[0m result[\u001b[39m'\u001b[39m\u001b[39mall_initial_softcounts\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m init_softcounts\n\u001b[0;32m     35\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(maxiter):\n\u001b[1;32m---> 36\u001b[0m     result \u001b[39m=\u001b[39m run(data, model, result[\u001b[39m'\u001b[39;49m\u001b[39mall_trans_softcounts\u001b[39;49m\u001b[39m'\u001b[39;49m], result[\u001b[39m'\u001b[39;49m\u001b[39mall_emission_softcounts\u001b[39;49m\u001b[39m'\u001b[39;49m], result[\u001b[39m'\u001b[39;49m\u001b[39mall_initial_softcounts\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m1\u001b[39;49m, parallel, fixed \u001b[39m=\u001b[39;49m fixed)\n\u001b[0;32m     37\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_resources):\n\u001b[0;32m     38\u001b[0m         result[\u001b[39m'\u001b[39m\u001b[39mall_trans_softcounts\u001b[39m\u001b[39m'\u001b[39m][j] \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39m\u001b[39mall_trans_softcounts\u001b[39m\u001b[39m'\u001b[39m][j]\u001b[39m.\u001b[39mtranspose()\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\site-packages\\pyBKT\\fit\\EM_fit.py:109\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(data, model, trans_softcounts, emission_softcounts, init_softcounts, num_outputs, parallel, fixed)\u001b[0m\n\u001b[0;32m    106\u001b[0m     thread_counts[thread_num]\u001b[39m.\u001b[39mupdate(\u001b[39minput\u001b[39m)\n\u001b[0;32m    108\u001b[0m p \u001b[39m=\u001b[39m Pool(\u001b[39mlen\u001b[39m(thread_counts))\n\u001b[1;32m--> 109\u001b[0m x \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mmap(inner, thread_counts)\n\u001b[0;32m    110\u001b[0m p\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    112\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\multiprocessing\\pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    363\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\multiprocessing\\pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 768\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[0;32m    770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\multiprocessing\\pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate with the default RMSE then specify AUC.\n",
    "model.fit(data = train_df)\n",
    "training_rmse = model.evaluate(data = df)\n",
    "training_auc = model.evaluate(data = train_df, metric = 'auc')\n",
    "print(\"Training RMSE: %f\" % training_rmse)\n",
    "print(\"Training AUC: %f\" % training_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAE: 0.485792\n"
     ]
    }
   ],
   "source": [
    "#define own metric\n",
    "def mae(true_vals, pred_vals):\n",
    "  \"\"\" Calculates the mean absolute error. \"\"\"\n",
    "  return np.mean(np.abs(true_vals - pred_vals))\n",
    "\n",
    "training_mae = model.evaluate(data = train_df, metric = mae)\n",
    "print(\"Training MAE: %f\" % training_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4971318371263319"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uses default as RMSE method.\n",
    "model.evaluate(data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4971318371263319,\n",
       " 0.6615384615384615,\n",
       " 0.5881732439811367,\n",
       " 0.49033123152983804]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data=df, metric=['rmse','accuracy','auc', 'mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seed = 60, num_fits = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anon Student Id</th>\n",
       "      <th>KC(Default)</th>\n",
       "      <th>Correct First Attempt</th>\n",
       "      <th>correct_predictions</th>\n",
       "      <th>state_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Geometry</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.24517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>Fractions</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.60850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>Algebra</td>\n",
       "      <td>0</td>\n",
       "      <td>0.31582</td>\n",
       "      <td>0.45925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>4</td>\n",
       "      <td>Numbers and Geometry and Percentages</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.27829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5</td>\n",
       "      <td>Ratio and Proportion</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.77434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6</td>\n",
       "      <td>Ratio and Proportion</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.77434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>6</td>\n",
       "      <td>Numbers and Percentages and Ratio and Proportion</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.08119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>6</td>\n",
       "      <td>Algebra and Fractions</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.67898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>7</td>\n",
       "      <td>Numbers and Geometry and Percentages</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.27829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>8</td>\n",
       "      <td>Numbers and Geometry and Fractions</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.78765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Anon Student Id                                       KC(Default)  \\\n",
       "6                  1                                          Geometry   \n",
       "104                2                                         Fractions   \n",
       "68                 3                                           Algebra   \n",
       "173                4              Numbers and Geometry and Percentages   \n",
       "33                 5                              Ratio and Proportion   \n",
       "46                 6                              Ratio and Proportion   \n",
       "228                6  Numbers and Percentages and Ratio and Proportion   \n",
       "150                6                             Algebra and Fractions   \n",
       "177                7              Numbers and Geometry and Percentages   \n",
       "190                8                Numbers and Geometry and Fractions   \n",
       "\n",
       "     Correct First Attempt  correct_predictions  state_predictions  \n",
       "6                        1              0.50000            0.24517  \n",
       "104                      1              0.50000            0.60850  \n",
       "68                       0              0.31582            0.45925  \n",
       "173                      1              0.50000            0.27829  \n",
       "33                       1              0.50000            0.77434  \n",
       "46                       1              0.50000            0.77434  \n",
       "228                      0              0.50000            0.08119  \n",
       "150                      0              0.50000            0.67898  \n",
       "177                      1              0.50000            0.27829  \n",
       "190                      1              0.50000            0.78765  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data = train_df) #Trained on all skills\n",
    "preds = model.predict(data = test_df)\n",
    "preds[['Anon Student Id', 'KC(Default)', 'Correct First Attempt', \n",
    "       'correct_predictions', 'state_predictions']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Algebra'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for all skills that have been trained and used for predict\n",
    "preds[preds['correct_predictions'] != 0.5]['KC(Default)'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Cross-Validation and Variants\n",
    "\n",
    "Crossvalidation is offered as a blackbox function similar to a combination of fit and evaluate that accepts a particular number of folds, a seed, and a metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Note that folds is an optional parameter as well as the model \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# variant, seed, and crossvalidated metric.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# By default, we crossvalidate on all skills separately.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model\u001b[39m.\u001b[39;49mcrossvalidate(data\u001b[39m=\u001b[39;49m df, folds \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\site-packages\\pyBKT\\models\\Model.py:250\u001b[0m, in \u001b[0;36mModel.crossvalidate\u001b[1;34m(self, data, data_path, metric, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_param([\u001b[39m'\u001b[39m\u001b[39mskills\u001b[39m\u001b[39m'\u001b[39m], {\u001b[39m'\u001b[39m\u001b[39mskills\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlist\u001b[39m(all_data\u001b[39m.\u001b[39mkeys())})\n\u001b[0;32m    249\u001b[0m \u001b[39mfor\u001b[39;00m skill \u001b[39min\u001b[39;00m all_data:\n\u001b[1;32m--> 250\u001b[0m     metric_vals[skill] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_crossvalidate(all_data[skill], skill, metric)\n\u001b[0;32m    251\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_param_init \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_model \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\site-packages\\pyBKT\\models\\Model.py:463\u001b[0m, in \u001b[0;36mModel._crossvalidate\u001b[1;34m(self, data, skill, metric)\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m crossvalidate\u001b[39m.\u001b[39mcrossvalidate(\u001b[39mself\u001b[39m, data, skill, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfolds, metric, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    462\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m crossvalidate\u001b[39m.\u001b[39;49mcrossvalidate(\u001b[39mself\u001b[39;49m, data, skill, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfolds, metric, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseed)\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\site-packages\\pyBKT\\util\\crossvalidate.py:135\u001b[0m, in \u001b[0;36mcrossvalidate\u001b[1;34m(model, data, skill, folds, metric, seed, use_folds)\u001b[0m\n\u001b[0;32m    132\u001b[0m train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((shuffle[\u001b[39m0\u001b[39m: iteration \u001b[39m*\u001b[39m split_size], shuffle[(iteration \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m split_size:\n\u001b[0;32m    133\u001b[0m                                                                     \u001b[39mlen\u001b[39m(data[\u001b[39m\"\u001b[39m\u001b[39mstarts\u001b[39m\u001b[39m\"\u001b[39m])]))\n\u001b[0;32m    134\u001b[0m training_data \u001b[39m=\u001b[39m fix_data(data, train)\n\u001b[1;32m--> 135\u001b[0m model\u001b[39m.\u001b[39mfit_model[skill] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49m_fit(training_data, skill, model\u001b[39m.\u001b[39;49mforgets)\n\u001b[0;32m    137\u001b[0m test \u001b[39m=\u001b[39m shuffle[iteration\u001b[39m*\u001b[39msplit_size:(iteration\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39msplit_size]\n\u001b[0;32m    138\u001b[0m test_data \u001b[39m=\u001b[39m fix_data(data, test)\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\site-packages\\pyBKT\\models\\Model.py:424\u001b[0m, in \u001b[0;36mModel._fit\u001b[1;34m(self, data, skill, forgets, preload)\u001b[0m\n\u001b[0;32m    422\u001b[0m             optional_args[\u001b[39m'\u001b[39m\u001b[39mfixed\u001b[39m\u001b[39m'\u001b[39m][var] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfixed[skill][var]\n\u001b[0;32m    423\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m preload:\n\u001b[1;32m--> 424\u001b[0m     fitmodel, log_likelihoods \u001b[39m=\u001b[39m EM_fit\u001b[39m.\u001b[39mEM_fit(fitmodel, data, parallel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptional_args)\n\u001b[0;32m    425\u001b[0m     \u001b[39mif\u001b[39;00m log_likelihoods[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m best_likelihood:\n\u001b[0;32m    426\u001b[0m         best_likelihood \u001b[39m=\u001b[39m log_likelihoods[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\site-packages\\pyBKT\\fit\\EM_fit.py:36\u001b[0m, in \u001b[0;36mEM_fit\u001b[1;34m(model, data, tol, maxiter, parallel, fixed)\u001b[0m\n\u001b[0;32m     33\u001b[0m result[\u001b[39m'\u001b[39m\u001b[39mall_initial_softcounts\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m init_softcounts\n\u001b[0;32m     35\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(maxiter):\n\u001b[1;32m---> 36\u001b[0m     result \u001b[39m=\u001b[39m run(data, model, result[\u001b[39m'\u001b[39;49m\u001b[39mall_trans_softcounts\u001b[39;49m\u001b[39m'\u001b[39;49m], result[\u001b[39m'\u001b[39;49m\u001b[39mall_emission_softcounts\u001b[39;49m\u001b[39m'\u001b[39;49m], result[\u001b[39m'\u001b[39;49m\u001b[39mall_initial_softcounts\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m1\u001b[39;49m, parallel, fixed \u001b[39m=\u001b[39;49m fixed)\n\u001b[0;32m     37\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_resources):\n\u001b[0;32m     38\u001b[0m         result[\u001b[39m'\u001b[39m\u001b[39mall_trans_softcounts\u001b[39m\u001b[39m'\u001b[39m][j] \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39m\u001b[39mall_trans_softcounts\u001b[39m\u001b[39m'\u001b[39m][j]\u001b[39m.\u001b[39mtranspose()\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\site-packages\\pyBKT\\fit\\EM_fit.py:108\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(data, model, trans_softcounts, emission_softcounts, init_softcounts, num_outputs, parallel, fixed)\u001b[0m\n\u001b[0;32m    105\u001b[0m     thread_counts[thread_num] \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39msequence_idx_start\u001b[39m\u001b[39m'\u001b[39m: sequence_idx_start, \u001b[39m'\u001b[39m\u001b[39msequence_idx_end\u001b[39m\u001b[39m'\u001b[39m: sequence_idx_end}\n\u001b[0;32m    106\u001b[0m     thread_counts[thread_num]\u001b[39m.\u001b[39mupdate(\u001b[39minput\u001b[39m)\n\u001b[1;32m--> 108\u001b[0m p \u001b[39m=\u001b[39m Pool(\u001b[39mlen\u001b[39;49m(thread_counts))\n\u001b[0;32m    109\u001b[0m x \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mmap(inner, thread_counts)\n\u001b[0;32m    110\u001b[0m p\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\multiprocessing\\context.py:119\u001b[0m, in \u001b[0;36mBaseContext.Pool\u001b[1;34m(self, processes, initializer, initargs, maxtasksperchild)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''Returns a process pool object'''\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpool\u001b[39;00m \u001b[39mimport\u001b[39;00m Pool\n\u001b[1;32m--> 119\u001b[0m \u001b[39mreturn\u001b[39;00m Pool(processes, initializer, initargs, maxtasksperchild,\n\u001b[0;32m    120\u001b[0m             context\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_context())\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\multiprocessing\\pool.py:235\u001b[0m, in \u001b[0;36mPool.__init__\u001b[1;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_worker_handler\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_worker_handler\u001b[39m.\u001b[39m_state \u001b[39m=\u001b[39m RUN\n\u001b[1;32m--> 235\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_worker_handler\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m    238\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_handler \u001b[39m=\u001b[39m threading\u001b[39m.\u001b[39mThread(\n\u001b[0;32m    239\u001b[0m     target\u001b[39m=\u001b[39mPool\u001b[39m.\u001b[39m_handle_tasks,\n\u001b[0;32m    240\u001b[0m     args\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_taskqueue, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_quick_put, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outqueue,\n\u001b[0;32m    241\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache)\n\u001b[0;32m    242\u001b[0m     )\n\u001b[0;32m    243\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_handler\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\threading.py:940\u001b[0m, in \u001b[0;36mThread.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[39mdel\u001b[39;00m _limbo[\u001b[39mself\u001b[39m]\n\u001b[0;32m    939\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m--> 940\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_started\u001b[39m.\u001b[39;49mwait()\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    608\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mc:\\Users\\91861\\anaconda3\\envs\\myenv\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Note that folds is an optional parameter as well as the model \n",
    "# variant, seed, and crossvalidated metric.\n",
    "# By default, we crossvalidate on all skills separately.\n",
    "model.crossvalidate(data= df, folds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that folds is an optional parameter as well as the model \n",
    "# variant, seed, and crossvalidated metric.\n",
    "# By default, we crossvalidate on all skills separately.\n",
    "model.crossvalidate(data=df, folds = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring all the model variants offered within pyBKT for one particular skill (Algebra) using cross-validation since it provides a much better evaluation of true model performance during test time than the training loss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seed = 60, num_fits = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this with a different skill or metric by replacing the lines below.\n",
    "skill = 'Algebra'\n",
    "metric = 'rmse'\n",
    "\n",
    "simple_cv = model.crossvalidate(data = test_df, skills = skill, \n",
    "                                metric = metric)\n",
    "simple_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. KT-IDEM - *multigs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seed = 60, num_fits = 1)\n",
    "multigs_cv = model.crossvalidate(data= test_df, skills = skill,\n",
    "                                 multigs = True, metric = metric)\n",
    "multigs_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Item Learning Effect - *multilearn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seed = 60, num_fits = 1)\n",
    "multilearn_cv = model.crossvalidate(data= test_df, skills = skill,\n",
    "                                    multilearn =\"question_id\", \n",
    "                                    metric = metric)\n",
    "multilearn_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. KT-PPS - *multiprior*\n",
    "4. Item Order Effect - *multipair*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seed = 60, num_fits = 1)\n",
    "# The multiprior model generates different priors based on the first \n",
    "# response of each student.\n",
    "multiprior_cv = model.crossvalidate(data= test_df, skills = skill,\n",
    "                                    multiprior = True, metric = metric,\n",
    "                                    folds = 3)\n",
    "                                    \n",
    "model = Model(seed = 60, num_fits = 1)\n",
    "multipair_cv = model.crossvalidate(data = test_df, skills = skill,\n",
    "                                   multipair = True, metric = metric,\n",
    "                                   folds = 3)\n",
    "\n",
    "pd.concat([multiprior_cv, multipair_cv], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "models = ['Standard', 'KT-IDEM', 'Item Learning Effect', 'KT-PPS', 'Item Order Effect', 'Combination']\n",
    "combined_skills = [0.55087, 0.43244, 0.57276, 0.45511, 0.50381, 0.43873]\n",
    "separate_skills = [0.48903, 0.37853, 0.50329, 0.41249, 0.49380, 0.42418]\n",
    "cs_under_16 = [0.34187, 0.30619, 0.30632, 0.39220, 0.32142, 0.30619]\n",
    "cs_above_16 = [0.44090, 0.43839, 0.42890, 0.45552, 0.59153, 0.43985]\n",
    "ss_under_16 = [0.50494, 0.41366, 0.50991, 0.51205, 0.51819, 0.41514]\n",
    "ss_above_16 = [0.51795, 0.55957, 0.51338, 0.44856, 0.52137, 0.52846]\n",
    "\n",
    "# Create line plots with specified colors\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create a list of colors in rainbow order\n",
    "colors = plt.cm.rainbow([0.1, 0.3, 0.4, 0.7, 0.85, 1.1])\n",
    "\n",
    "plt.plot(models, combined_skills, marker='o', label='Combined Skills', color=colors[0])\n",
    "plt.plot(models, separate_skills, marker='o', label='Separate Skills', color=colors[1])\n",
    "plt.plot(models, cs_under_16, marker='o', label='CS_Under 16', color=colors[2])\n",
    "plt.plot(models, cs_above_16, marker='o', label='CS_Above 16', color=colors[3])\n",
    "plt.plot(models, ss_under_16, marker='o', label='SS_Under 16', color=colors[4])\n",
    "plt.plot(models, ss_above_16, marker='o', label='SS_Above 16', color=colors[5])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data (replace with your actual data)\n",
    "skills = ['G', 'N & G & F', 'A',\n",
    "          'N & P & R', 'N & A & F', 'A & F', 'N & G & P', 'R']\n",
    "under16_correct = [0.70588, 0.73684, 0.34334, 0.72222, 0.64286, 0.66667, 0.56250, 0.70000]\n",
    "above16_correct = [0.40000, 0.75000, 0.22411, 0.66667, 0.60000, 0.50000, 0.60000, 0.25000]\n",
    "under16_state = [0.43162, 0.34910, 0.00202, 0.94924, 0.58256, 0.75186, 0.62147, 0.70336]\n",
    "above16_state = [0.28383, 0.72760, 0.00210, 0.89165, 0.63521, 0.62821, 0.55802, 0.86443]\n",
    "\n",
    "# Create line plots for correct predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(skills, under16_correct, marker='o', label='Under16')\n",
    "plt.plot(skills, above16_correct, marker='o', label='Above16')\n",
    "plt.xlabel('Skills')\n",
    "plt.ylabel('Correct Predictions')\n",
    "plt.title('Correct Predictions by Skill and Age Group')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create line plots for state predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(skills, under16_state, marker='o', label='Under16')\n",
    "plt.plot(skills, above16_state, marker='o', label='Above16')\n",
    "plt.xlabel('Skills')\n",
    "plt.ylabel('State Predictions')\n",
    "plt.title('State Predictions by Skill and Age Group')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data (replace with your actual data)\n",
    "skills = ['G', 'N & G & F', 'A',\n",
    "          'N & P & R', 'N & A & F', 'A & F', 'N & G & P', 'R']\n",
    "under16_correct = [0.70588, 0.73684, 0.34334, 0.72222, 0.64286, 0.66667, 0.56250, 0.70000]\n",
    "above16_correct = [0.40000, 0.75000, 0.22411, 0.66667, 0.60000, 0.50000, 0.60000, 0.25000]\n",
    "under16_state = [0.43162, 0.34910, 0.00202, 0.94924, 0.58256, 0.75186, 0.62147, 0.70336]\n",
    "above16_state = [0.28383, 0.72760, 0.00210, 0.89165, 0.63521, 0.62821, 0.55802, 0.86443]\n",
    "\n",
    "# Create line plots for correct predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(skills, under16_correct, marker='o', label='Under16')\n",
    "plt.plot(skills, above16_correct, marker='o', label='Above16')\n",
    "plt.xlabel('Skills')\n",
    "plt.ylabel('Correct Predictions')\n",
    "plt.title('Correct Predictions by Skill and Age Group')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create line plots for state predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(skills, under16_state, marker='o', label='Under16')\n",
    "plt.plot(skills, above16_state, marker='o', label='Above16')\n",
    "plt.xlabel('Skills')\n",
    "plt.ylabel('State Predictions')\n",
    "plt.title('State Predictions by Skill and Age Group')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Parameter Initialization and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seed = 60, num_fits = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill = 'Geometry'\n",
    "\n",
    "model.coef_ = {skill: {'prior': 1e-40}}\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the pre-initialized parameters.\n",
    "model.fit(data = train_df, multigs = True)\n",
    "low_prior_auc = model.evaluate(data = train_df, metric = 'auc')\n",
    "\n",
    "# We can obtain the prior value by indexing into the model.coef_\n",
    "# dictionary with the skill and parameter names. \n",
    "print(\"Fitted Prior Value: %f\" % model.coef_[skill]['prior'])\n",
    "print(\"Training AUC: %f\" % low_prior_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the prior to be more reasonable.\n",
    "model.coef_ = {skill: {'prior': 0.5}}\n",
    "model.fit(data_path = 'CS.csv', multigs = True)\n",
    "normal_prior_auc = model.evaluate(data_path = 'CS.csv', metric = 'auc')\n",
    "\n",
    "# Print the fitted prior value and RMSE.\n",
    "print(\"Fitted Prior Value: %f\" % model.coef_[skill]['prior'])\n",
    "print(\"Training AUC: %f\" % normal_prior_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seed = 60, num_fits = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data_path = 'CS.csv', skills = skill,\n",
    "          forgets = True, multilearn = True, \n",
    "          multigs = True)\n",
    "model.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame containing the 'KC(Default)' column\n",
    "df = pd.read_csv(\"CS.csv\")\n",
    "\n",
    "# Create a list of unique skills\n",
    "skills = list(df['KC(Default)'].unique())\n",
    "\n",
    "# Create a dictionary comprehension to set the prior value for each skill\n",
    "model_coefs = {skill: {'prior': 1e-40} for skill in skills}\n",
    "\n",
    "# Display the resulting dictionary of skills with their corresponding prior values\n",
    "print(model_coefs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the pre-initialized parameters.\n",
    "model.fit(data_path='CS.csv', multigs=True)\n",
    "low_prior_auc = model.evaluate(data_path='CS.csv', metric='auc')\n",
    "\n",
    "# We can obtain the prior value by indexing into the model.coef_\n",
    "# dictionary with the skill and parameter names.\n",
    "\n",
    "# Assuming skills is a list containing unique skill names\n",
    "skills = list(df['KC(Default)'].unique())\n",
    "\n",
    "# Create an empty dictionary to store fitted prior values\n",
    "fitted_priors = {}\n",
    "\n",
    "for skill in skills:\n",
    "    # Access the prior value for each skill from the model.coef_ dictionary\n",
    "    fitted_prior = model.coef_[skill]['prior']\n",
    "    fitted_priors[skill] = fitted_prior\n",
    "\n",
    "# Display the fitted prior values for each skill\n",
    "print(\"Fitted Prior Values:\")\n",
    "for skill, prior in fitted_priors.items():\n",
    "    print(f\"{skill}: {prior}\")\n",
    "\n",
    "print(\"Training AUC:\", low_prior_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the prior to be more reasonable.\n",
    "model.coef_ = {}\n",
    "\n",
    "# Assuming skills is a list containing unique skill names\n",
    "skills = list(df['KC(Default)'].unique())\n",
    "\n",
    "# Create an empty dictionary to store fitted prior values for each skill\n",
    "fitted_priors = {}\n",
    "\n",
    "for skill in skills:\n",
    "    # Set the prior value for each skill to 0.5\n",
    "    model.coef_ = {skill: {'prior': 0.5}}\n",
    "\n",
    "    # Train the model with the pre-initialized parameters for each skill.\n",
    "    model.fit(data_path='CS.csv', multigs=True)\n",
    "    \n",
    "    # Evaluate the model with the current prior value for each skill.\n",
    "    normal_prior_auc = model.evaluate(data_path='CS.csv', metric='auc')\n",
    "    \n",
    "    # Store the fitted prior value for the skill in the fitted_priors dictionary.\n",
    "    fitted_priors[skill] = model.coef_[skill]['prior']\n",
    "\n",
    "    # Print the fitted prior value and training AUC for each skill.\n",
    "    print(\"Fitted Prior Value for Skill '%s': %f\" % (skill, fitted_priors[skill]))\n",
    "    print(\"Training AUC for Skill '%s': %f\" % (skill, normal_prior_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = list(df['KC(Default)'].unique())\n",
    "\n",
    "# Train the model with the pre-initialized parameters, including skills and other options.\n",
    "model.fit(data_path='CS.csv', skills=skills, forgets=False, multilearn=True, multigs=True)\n",
    "\n",
    "# Retrieve the model parameters\n",
    "model_params = model.params()\n",
    "\n",
    "# Print the model parameters\n",
    "print(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seed = 60, num_fits = 1)\n",
    "model.fit(data_path = 'CS.csv',\n",
    "          forgets = True, multilearn = True, \n",
    "          multigs = True)\n",
    "model.params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roster Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.fit(data_path = 'CS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roster = Roster(students = ['1', '2'], skills = 'Algebra', model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"User1's mastery (t = 0):\", roster.get_state_type('Algebra', '1'))\n",
    "print(\"User1's probability of mastery (t = 0):\", roster.get_mastery_prob('Algebra', '1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "User1_new_state = roster.update_state('Algebra','1', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"User1's mastery (t = 1):\", roster.get_state_type('Algebra', '1'))\n",
    "print(\"User1's probability of mastery (t = 1):\", roster.get_mastery_prob('Algebra', '1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roster.update_state('Algebra', '1', np.ones(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"User1's mastery (t = 11):\", roster.get_state_type('Algebra', '1'))\n",
    "print(\"User1's probability of mastery (t = 11):\", roster.get_mastery_prob('Algebra', '1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if roster.get_state_type('Algebra', '1') == StateType.MASTERED:\n",
    "    print(\"User1 has mastered the skill!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can update User2's state with two correct responses.\n",
    "roster.update_state('Algebra', '2', np.ones(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# He should remain unmastered.\n",
    "print(\"User2's mastery (t = 2):\", roster.get_state_type('Algebra', '2'))\n",
    "print(\"User2's probability of mastery (t = 2):\", roster.get_mastery_prob('Algebra', '2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can print aggregate statistics for mastery and correctness.\n",
    "print(\"Both students' probabilites of correctness:\", roster.get_correct_probs('Algebra'))\n",
    "print(\"Both students' probabilites of mastery:\", roster.get_mastery_probs('Algebra'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new student, User3.\n",
    "roster.add_student('Algebra', '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update User3's state with a sequence of correct and incorrect responses.\n",
    "User3_new_state = roster.update_state('Algebra', '3', np.array([1, 0, 1, 0, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print User3's correctness and mastery probability.\n",
    "print(\"User3's correctness probability:\", User3_new_state.get_correct_prob())\n",
    "print(\"User3's mastery probability:\", User3_new_state.get_mastery_prob())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete User2 from the roster.\n",
    "roster.remove_student('Algebra', '2')\n",
    "\n",
    "# Reset student's state (i.e. latent and observable).\n",
    "roster.reset_state('Algebra', '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User1 should be back to the initial prior as the mastery probability and should be unmastered.\n",
    "print(\"User1's mastery (t' = 0):\", roster.get_state_type('Algebra', '1'))\n",
    "print(\"User1's probability of mastery (t' = 0):\", roster.get_mastery_prob('Algebra', '1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IRT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IRT: \n",
    "    def __init__(self, lr, iterations, user_size, question_size) :\n",
    "        self.lr= lr\n",
    "        self.iterations= iterations\n",
    "        self.user_size= user_size\n",
    "        self.question_size= question_size\n",
    "        self.theta= np.zeros(user_size)\n",
    "        self.beta= np.zeros( question_size)\n",
    "        self.val_acc_lst= []\n",
    "        self.neg_lld_lst= []\n",
    "        self.val_lld_lst= []\n",
    "\n",
    "    def sigmoid( self, x):\n",
    "        return np.exp(x) / (1+np.exp(x))\n",
    "\n",
    "    def neg_log_lklihood(self, data):\n",
    "        log_lklihood= 0.\n",
    "        for ind in np.arange(len(data[\"is_correct\"])):\n",
    "            i = data[\"user_id\"][ind]\n",
    "            j= data[\"question_id\"][ind]\n",
    "            cij= data[\"is_correct\"][ind]\n",
    "\n",
    "            theta_i = self.theta[i]\n",
    "            beta_j = self. beta[j]\n",
    "            diff= theta_i - beta_j\n",
    "            log_lklihood += cij * diff- np.log(1+ np.exp(diff))\n",
    "        return-log_lklihood\n",
    "    \n",
    "    def update_theta_beta(self, data):\n",
    "        diff_theta_beta = np.expand_dims(self.theta, axis=1) - np.expand_dims(self.beta, axis= 0)\n",
    "        sig = self.sigmoid(diff_theta_beta)\n",
    "\n",
    "        grad_theta= np.zeros_like(diff_theta_beta)\n",
    "        grad_beta= np.zeros_like(diff_theta_beta)\n",
    "\n",
    "        for ind in np.arange(len(data[\"is_correct\"])):\n",
    "            i = data[\"user_id\"][ind]\n",
    "            j= data[\"question_id\"][ind]\n",
    "            cij= data[\"is_correct\"][ind]\n",
    "\n",
    "            grad_theta[i, j] = cij - sig[i,j]\n",
    "            grad_beta[i, j]= sig[i, j] -~ cij\n",
    "        \n",
    "        self.theta = self.theta + self.lr* np.sum(grad_theta, axis=1)\n",
    "        self.beta = self.beta + self.lr* np.sum(grad_beta, axis=0)\n",
    "\n",
    "    def evaluate(self, data):\n",
    "        pred=[]\n",
    "        for i, q in enumerate(data[\"question_id\"]):\n",
    "            u = data[\"user_id\"][i]\n",
    "            x= (self.theta[u]- self.beta[q]).sum()\n",
    "            p_a = self.sigmoid(x)\n",
    "            pred.append(p_a >=0.5)\n",
    "        return np.sum((data[\"is_correct\"] == np.array(pred)))/ len(data[\"is_correct\"])\n",
    "\n",
    "    def irt(self, train_data, val_data):\n",
    "        for i in range(self.iterations):\n",
    "            neg_lld = self.neg_log_lklihood(train_data)\n",
    "            score = self.evaluate(val_data)\n",
    "            self.val_acc_lst.append(score)\n",
    "            self.neg_lld_lst.append(neg_lld)\n",
    "            self.val_lld_lst.append(self.neg_log_lklihood(val_data))\n",
    "            print(\"NLLK: {} \\t Score: {}\".format(neg_lld, score))\n",
    "            self.update_theta_beta(train_data)\n",
    "\n",
    "        return self.theta, self.beta, self.val_acc_lst, self.neg_lld_lst, self.val_lld_lst                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(skill= 'Algebra'):\n",
    "    train_data= df[df['KC(Default)']== skill]\n",
    "    train_data= train_data[['Anon Student Id', 'Problem Name', 'Correct First Attempt']]\n",
    "    train_data.columns = ['user_id',\"question_id\", \"is_correct\"]\n",
    "\n",
    "    labels, levels = pd.factorize(train_data['user_id'])\n",
    "    train_data['user_id']= labels\n",
    "    user_dic= dict(zip(levels, list(range(len(levels)))))\n",
    "    labels, levels = pd.factorize(train_data['question_id'])\n",
    "    train_data['question_id']= labels\n",
    "    question_dic= dict(zip(levels, list(range(len(levels)))))\n",
    "\n",
    "    train_data, test_data = train_test_split(train_data, test_size=0.3)\n",
    "    val_data, test_data = train_test_split(test_data, test_size=0.3)\n",
    "\n",
    "    train_data= train_data.reset_index()\n",
    "    train_data= train_data.drop(columns=['index'])\n",
    "    test_data= test_data.reset_index()\n",
    "    test_data= test_data.drop(columns=['index'])\n",
    "    val_data= val_data.reset_index()\n",
    "    val_data= val_data.drop(columns=['index'])\n",
    "\n",
    "    lr =1e-2\n",
    "    num_iterations=50\n",
    "    irt_model=IRT(lr, num_iterations, len(user_dic), len(question_dic)) \n",
    "    theta, beta, val_acc_lst, neg_lld_lst, val_lld_lst= irt_model.irt(train_data, val_data)\n",
    "\n",
    "    print(\"Validation accuracy: {}\".format(val_acc_lst[-1]))\n",
    "    test_acc= irt_model.evaluate(test_data)\n",
    "    print(\"Test accuracy: {}\". format(test_acc))\n",
    "    return test_acc, user_dic, question_dic, theta, bytearray\n",
    "\n",
    "skill_list = list(df['KC(Default)'].unique())\n",
    "skill_acc = []\n",
    "\n",
    "for s in skill_list:\n",
    "    test_acc, user_dic, question_dic, theta, beta = main(s)\n",
    "    skill_acc.append((s, test_acc))\n",
    "\n",
    "for skill, acc in skill_acc:\n",
    "    print(f\"Skill: {skill}, Accuracy: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
