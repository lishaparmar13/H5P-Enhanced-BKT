{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyBKT.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seed = 60, num_fits = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fetch_dataset(\"https://raw.githubusercontent.com/lishaparmar13/H5P-Enhanced-BKT/main/Above16-CS.csv\",'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= pd.read_csv(r\"Above16-CS.csv\", encoding ='latin')\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data = df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data = train_df)\n",
    "print(\"Fitted Skills:\\n%s\" % '\\n'.join(model.coef_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate with the default RMSE then specify AUC.\n",
    "model.fit(data= df2)\n",
    "training_rmse = model.evaluate(data = df2)\n",
    "training_auc = model.evaluate(data = df2, metric = 'auc')\n",
    "print(\"Training RMSE: %f\" % training_rmse)\n",
    "print(\"Training AUC: %f\" % training_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define own metric\n",
    "def mae(true_vals, pred_vals):\n",
    "  \"\"\" Calculates the mean absolute error. \"\"\"\n",
    "  return np.mean(np.abs(true_vals - pred_vals))\n",
    "\n",
    "training_mae = model.evaluate(data = df2, metric = mae)\n",
    "print(\"Training MAE: %f\" % training_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seed = 60, num_fits = 1)\n",
    "model.fit(data = train_df)\n",
    "preds = model.predict(data = test_df)\n",
    "preds[['Anon Student Id', 'KC(Default)', 'Correct First Attempt', \n",
    "       'correct_predictions', 'state_predictions']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's sanity check that we have only trained on the skills that we \n",
    "# specified in the call to fit! Note that while it is possible for a \n",
    "# BKT prediction to be 0.5 exactly, it is unlikely.\n",
    "preds[preds['correct_predictions'] != 0.5]['KC(Default)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(data = df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(data=df2, metric=['rmse','accuracy','auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that folds is an optional parameter as well as the model \n",
    "# variant, seed, and crossvalidated metric.\n",
    "# By default, we crossvalidate on all skills separately.\n",
    "model.crossvalidate(data = df2, folds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seed = 60, num_fits = 1)\n",
    "# Try this with a different skill or metric by replacing the lines below.\n",
    "skill = 'Algebra'\n",
    "metric = 'rmse'\n",
    "\n",
    "simple_cv = model.crossvalidate(data = df2, skills = skill, \n",
    "                                metric = metric)\n",
    "simple_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seed = 60, num_fits = 1)\n",
    "skill = 'Algebra'\n",
    "\n",
    "multilearn_cv = model.crossvalidate(data = df2, skills = skill,\n",
    "                                    multilearn =\"Answer Type\", forgets = True, \n",
    "                                    metric = metric)\n",
    "multilearn_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seed = 60, num_fits = 1)\n",
    "multilearn_cv = model.crossvalidate(data= df2, skills = skill,\n",
    "                                    multilearn =\"question_id\", \n",
    "                                    metric = metric)\n",
    "multilearn_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seed = 60, num_fits = 1)\n",
    "# The multiprior model generates different priors based on the first \n",
    "# response of each student.\n",
    "multiprior_cv = model.crossvalidate(data= df2, skills = skill,\n",
    "                                    multiprior = True, metric = metric,\n",
    "                                    folds = 3)\n",
    "\n",
    "model = Model(seed = 60, num_fits = 1)\n",
    "multipair_cv = model.crossvalidate(data = df2, skills = skill,\n",
    "                                   multipair = True, metric = metric,\n",
    "                                   folds = 3)\n",
    "\n",
    "pd.concat([multiprior_cv, multipair_cv], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(seed = 60, num_fits = 1)\n",
    "# We combine the fifth parameter, forgets, with the previous multilearn\n",
    "# and multiguess/slip models for a combo model.\n",
    "combo_cv = model.crossvalidate(data = df2, skills = skill,\n",
    "                               forgets = True, multilearn = True, \n",
    "                               multigs = True, metric = metric)\n",
    "combo_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill = 'Geometry'\n",
    "\n",
    "model.coef_ = {skill: {'prior': 1e-40}}\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the pre-initialized parameters.\n",
    "model.fit(data = df2, multigs = True)\n",
    "low_prior_auc = model.evaluate(data = df2, metric = 'auc')\n",
    "\n",
    "# We can obtain the prior value by indexing into the model.coef_\n",
    "# dictionary with the skill and parameter names. \n",
    "print(\"Fitted Prior Value: %f\" % model.coef_[skill]['prior'])\n",
    "print(\"Training AUC: %f\" % low_prior_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the prior to be more reasonable.\n",
    "model.coef_ = {skill: {'prior': 0.5}}\n",
    "model.fit(data= df2, multigs = True)\n",
    "normal_prior_auc = model.evaluate(data= df2, metric = 'auc')\n",
    "\n",
    "# Print the fitted prior value and RMSE.\n",
    "print(\"Fitted Prior Value: %f\" % model.coef_[skill]['prior'])\n",
    "print(\"Training AUC: %f\" % normal_prior_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data=df2, forgets = True, multilearn = True, skills=skill, \n",
    "          multigs = True)\n",
    "model.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data=df2, forgets = True, multilearn = True, \n",
    "          multigs = True)\n",
    "model.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
